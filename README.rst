========================================================================
Symmetry Based Representation Learning through Homomorphism AutoEncoders
========================================================================

Implementation associated with the paper [Homomorphism Autoencoder -- Learning Group Structured Representations from Observed Transitions](https://arxiv.org/abs/2207.12067)

---

The Homomorphism AutoEncoder HAE is a model trained on observed transitions :math:`(o_t, g_t, o_{t+1})` to jointly learn a group representation of the observed actions :math:`g_t` and a representation of the observations :math:`o`.

Main scripts are provided in "./displacementae/homomorphism/".

Run commands are provided in the "./displacementae/homomorphism/README.rst".
